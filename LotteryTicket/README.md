"Lottery Ticket Hypothesis" : Dense, randomly-initialized, feed-forward and/or convolutional networks contain subnetworks ("winning tickets") that - when trained in isolation - reach test accuracy comparable to the original network in a similar number of iterations. The winning tickets we find have won the initialization lottery: their connections have initial weights that makes training particularly effective.

Citation:
<pre>
@misc{frankle2018lottery,
    title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
    author={Jonathan Frankle and Michael Carbin},
    year={2018},
    eprint={1803.03635},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
</pre>
